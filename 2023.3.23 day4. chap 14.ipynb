{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20be0129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3      4     5     6       7     8     9    10  11  12\n",
       "0   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4   5   1\n",
       "1   7.8  0.88  0.00  2.6  0.098  25.0  67.0  0.9968  3.20  0.68  9.8   5   1\n",
       "2   7.8  0.76  0.04  2.3  0.092  15.0  54.0  0.9970  3.26  0.65  9.8   5   1\n",
       "3  11.2  0.28  0.56  1.9  0.075  17.0  60.0  0.9980  3.16  0.58  9.8   6   1\n",
       "4   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4   5   1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 와인의 종류 예측하기\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/data/wine.csv', header=None)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a80961a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.iloc[:,0:-1]\n",
    "y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6409ca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 학습용과 테스트용으로 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8604c876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 37ms/step - loss: 0.8110 - accuracy: 0.7524 - val_loss: 0.6552 - val_accuracy: 0.7338\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5978 - accuracy: 0.7331 - val_loss: 0.4998 - val_accuracy: 0.7562\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4607 - accuracy: 0.7549 - val_loss: 0.3905 - val_accuracy: 0.7762\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3763 - accuracy: 0.8099 - val_loss: 0.3371 - val_accuracy: 0.8577\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3272 - accuracy: 0.8619 - val_loss: 0.2868 - val_accuracy: 0.8823\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2876 - accuracy: 0.8820 - val_loss: 0.2509 - val_accuracy: 0.9085\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2572 - accuracy: 0.9066 - val_loss: 0.2229 - val_accuracy: 0.9254\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2368 - accuracy: 0.9274 - val_loss: 0.2050 - val_accuracy: 0.9431\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2214 - accuracy: 0.9317 - val_loss: 0.1920 - val_accuracy: 0.9408\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2147 - accuracy: 0.9323 - val_loss: 0.1860 - val_accuracy: 0.9423\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2098 - accuracy: 0.9323 - val_loss: 0.1797 - val_accuracy: 0.9431\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2066 - accuracy: 0.9310 - val_loss: 0.1795 - val_accuracy: 0.9415\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2041 - accuracy: 0.9317 - val_loss: 0.1744 - val_accuracy: 0.9431\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2013 - accuracy: 0.9312 - val_loss: 0.1741 - val_accuracy: 0.9408\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1997 - accuracy: 0.9315 - val_loss: 0.1713 - val_accuracy: 0.9415\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1991 - accuracy: 0.9320 - val_loss: 0.1713 - val_accuracy: 0.9408\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1976 - accuracy: 0.9305 - val_loss: 0.1698 - val_accuracy: 0.9408\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1963 - accuracy: 0.9315 - val_loss: 0.1686 - val_accuracy: 0.9431\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1953 - accuracy: 0.9330 - val_loss: 0.1676 - val_accuracy: 0.9415\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1954 - accuracy: 0.9317 - val_loss: 0.1674 - val_accuracy: 0.9415\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1956 - accuracy: 0.9338 - val_loss: 0.1645 - val_accuracy: 0.9431\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1925 - accuracy: 0.9341 - val_loss: 0.1667 - val_accuracy: 0.9462\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1918 - accuracy: 0.9338 - val_loss: 0.1633 - val_accuracy: 0.9438\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1904 - accuracy: 0.9346 - val_loss: 0.1640 - val_accuracy: 0.9446\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1902 - accuracy: 0.9338 - val_loss: 0.1608 - val_accuracy: 0.9431\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1885 - accuracy: 0.9353 - val_loss: 0.1622 - val_accuracy: 0.9454\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1873 - accuracy: 0.9351 - val_loss: 0.1592 - val_accuracy: 0.9423\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1866 - accuracy: 0.9356 - val_loss: 0.1597 - val_accuracy: 0.9446\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1857 - accuracy: 0.9358 - val_loss: 0.1583 - val_accuracy: 0.9454\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1850 - accuracy: 0.9361 - val_loss: 0.1567 - val_accuracy: 0.9431\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1834 - accuracy: 0.9366 - val_loss: 0.1561 - val_accuracy: 0.9454\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1820 - accuracy: 0.9371 - val_loss: 0.1544 - val_accuracy: 0.9438\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1805 - accuracy: 0.9376 - val_loss: 0.1537 - val_accuracy: 0.9485\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1792 - accuracy: 0.9379 - val_loss: 0.1498 - val_accuracy: 0.9469\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1769 - accuracy: 0.9387 - val_loss: 0.1508 - val_accuracy: 0.9485\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1758 - accuracy: 0.9392 - val_loss: 0.1517 - val_accuracy: 0.9500\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1739 - accuracy: 0.9397 - val_loss: 0.1472 - val_accuracy: 0.9500\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1716 - accuracy: 0.9410 - val_loss: 0.1453 - val_accuracy: 0.9515\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1702 - accuracy: 0.9405 - val_loss: 0.1459 - val_accuracy: 0.9523\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1683 - accuracy: 0.9407 - val_loss: 0.1431 - val_accuracy: 0.9508\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1674 - accuracy: 0.9420 - val_loss: 0.1451 - val_accuracy: 0.9562\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1660 - accuracy: 0.9402 - val_loss: 0.1407 - val_accuracy: 0.9531\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1622 - accuracy: 0.9430 - val_loss: 0.1358 - val_accuracy: 0.9523\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1598 - accuracy: 0.9418 - val_loss: 0.1345 - val_accuracy: 0.9554\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1559 - accuracy: 0.9425 - val_loss: 0.1281 - val_accuracy: 0.9531\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1510 - accuracy: 0.9435 - val_loss: 0.1305 - val_accuracy: 0.9531\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1476 - accuracy: 0.9441 - val_loss: 0.1236 - val_accuracy: 0.9546\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1458 - accuracy: 0.9469 - val_loss: 0.1200 - val_accuracy: 0.9546\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1482 - accuracy: 0.9448 - val_loss: 0.1194 - val_accuracy: 0.9546\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1438 - accuracy: 0.9461 - val_loss: 0.1205 - val_accuracy: 0.9554\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1402 - accuracy: 0.9482 - val_loss: 0.1189 - val_accuracy: 0.9577\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1391 - accuracy: 0.9477 - val_loss: 0.1219 - val_accuracy: 0.9585\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1380 - accuracy: 0.9489 - val_loss: 0.1203 - val_accuracy: 0.9600\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1357 - accuracy: 0.9512 - val_loss: 0.1127 - val_accuracy: 0.9554\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1349 - accuracy: 0.9497 - val_loss: 0.1113 - val_accuracy: 0.9569\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1329 - accuracy: 0.9477 - val_loss: 0.1126 - val_accuracy: 0.9600\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1330 - accuracy: 0.9505 - val_loss: 0.1157 - val_accuracy: 0.9615\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1301 - accuracy: 0.9505 - val_loss: 0.1122 - val_accuracy: 0.9623\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1293 - accuracy: 0.9515 - val_loss: 0.1104 - val_accuracy: 0.9623\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1280 - accuracy: 0.9518 - val_loss: 0.1103 - val_accuracy: 0.9623\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1277 - accuracy: 0.9525 - val_loss: 0.1084 - val_accuracy: 0.9631\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1260 - accuracy: 0.9523 - val_loss: 0.1119 - val_accuracy: 0.9615\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1263 - accuracy: 0.9533 - val_loss: 0.1061 - val_accuracy: 0.9623\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1234 - accuracy: 0.9525 - val_loss: 0.1044 - val_accuracy: 0.9638\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1222 - accuracy: 0.9536 - val_loss: 0.1103 - val_accuracy: 0.9638\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1228 - accuracy: 0.9548 - val_loss: 0.1086 - val_accuracy: 0.9638\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1225 - accuracy: 0.9571 - val_loss: 0.1006 - val_accuracy: 0.9677\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1208 - accuracy: 0.9546 - val_loss: 0.1000 - val_accuracy: 0.9654\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1212 - accuracy: 0.9546 - val_loss: 0.0997 - val_accuracy: 0.9646\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1195 - accuracy: 0.9551 - val_loss: 0.0995 - val_accuracy: 0.9646\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1165 - accuracy: 0.9559 - val_loss: 0.1015 - val_accuracy: 0.9662\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1163 - accuracy: 0.9564 - val_loss: 0.0986 - val_accuracy: 0.9662\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1161 - accuracy: 0.9592 - val_loss: 0.0969 - val_accuracy: 0.9654\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1181 - accuracy: 0.9559 - val_loss: 0.0967 - val_accuracy: 0.9646\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1166 - accuracy: 0.9551 - val_loss: 0.0953 - val_accuracy: 0.9685\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1149 - accuracy: 0.9577 - val_loss: 0.0980 - val_accuracy: 0.9685\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1134 - accuracy: 0.9556 - val_loss: 0.0975 - val_accuracy: 0.9692\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1117 - accuracy: 0.9574 - val_loss: 0.1056 - val_accuracy: 0.9677\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1122 - accuracy: 0.9587 - val_loss: 0.0928 - val_accuracy: 0.9685\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1121 - accuracy: 0.9589 - val_loss: 0.0923 - val_accuracy: 0.9723\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1124 - accuracy: 0.9577 - val_loss: 0.0923 - val_accuracy: 0.9731\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1091 - accuracy: 0.9595 - val_loss: 0.0915 - val_accuracy: 0.9677\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1082 - accuracy: 0.9602 - val_loss: 0.0917 - val_accuracy: 0.9723\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1071 - accuracy: 0.9630 - val_loss: 0.0905 - val_accuracy: 0.9685\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1087 - accuracy: 0.9615 - val_loss: 0.0905 - val_accuracy: 0.9715\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1092 - accuracy: 0.9610 - val_loss: 0.0977 - val_accuracy: 0.9592\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1145 - accuracy: 0.9574 - val_loss: 0.0890 - val_accuracy: 0.9700\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1081 - accuracy: 0.9571 - val_loss: 0.0981 - val_accuracy: 0.9700\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1076 - accuracy: 0.9600 - val_loss: 0.1010 - val_accuracy: 0.9685\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1052 - accuracy: 0.9620 - val_loss: 0.0925 - val_accuracy: 0.9731\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1031 - accuracy: 0.9630 - val_loss: 0.0892 - val_accuracy: 0.9715\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1019 - accuracy: 0.9630 - val_loss: 0.0865 - val_accuracy: 0.9762\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1013 - accuracy: 0.9641 - val_loss: 0.0858 - val_accuracy: 0.9762\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1019 - accuracy: 0.9656 - val_loss: 0.0853 - val_accuracy: 0.9738\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1015 - accuracy: 0.9636 - val_loss: 0.0848 - val_accuracy: 0.9762\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1055 - accuracy: 0.9592 - val_loss: 0.0921 - val_accuracy: 0.9723\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1051 - accuracy: 0.9613 - val_loss: 0.0986 - val_accuracy: 0.9715\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0978 - accuracy: 0.9656 - val_loss: 0.0830 - val_accuracy: 0.9746\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0982 - accuracy: 0.9661 - val_loss: 0.0862 - val_accuracy: 0.9708\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1020 - accuracy: 0.9636 - val_loss: 0.0853 - val_accuracy: 0.9754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x250ffbe3f10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 실행\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=500, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a074d01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step - loss: 0.0838 - accuracy: 0.9723\n"
     ]
    }
   ],
   "source": [
    "# 모델 결과 출력\n",
    "score = model.evaluate(X_test, y_test)\n",
    "# print(\"Test loss :\", score[0], \"Test accuracy : \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c24350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check point를 통해 모델 업데이트\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a31e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./data/data/model/all/{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=model_path, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b68f942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44400a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to ./data/data/model/all\\01-0.2438.hdf5\n",
      "\n",
      "Epoch 2: saving model to ./data/data/model/all\\02-0.2438.hdf5\n",
      "\n",
      "Epoch 3: saving model to ./data/data/model/all\\03-0.2354.hdf5\n",
      "\n",
      "Epoch 4: saving model to ./data/data/model/all\\04-0.2400.hdf5\n",
      "\n",
      "Epoch 5: saving model to ./data/data/model/all\\05-0.2308.hdf5\n",
      "\n",
      "Epoch 6: saving model to ./data/data/model/all\\06-0.4762.hdf5\n",
      "\n",
      "Epoch 7: saving model to ./data/data/model/all\\07-0.8562.hdf5\n",
      "\n",
      "Epoch 8: saving model to ./data/data/model/all\\08-0.8985.hdf5\n",
      "\n",
      "Epoch 9: saving model to ./data/data/model/all\\09-0.9100.hdf5\n",
      "\n",
      "Epoch 10: saving model to ./data/data/model/all\\10-0.9169.hdf5\n",
      "\n",
      "Epoch 11: saving model to ./data/data/model/all\\11-0.9215.hdf5\n",
      "\n",
      "Epoch 12: saving model to ./data/data/model/all\\12-0.9254.hdf5\n",
      "\n",
      "Epoch 13: saving model to ./data/data/model/all\\13-0.9285.hdf5\n",
      "\n",
      "Epoch 14: saving model to ./data/data/model/all\\14-0.9315.hdf5\n",
      "\n",
      "Epoch 15: saving model to ./data/data/model/all\\15-0.9323.hdf5\n",
      "\n",
      "Epoch 16: saving model to ./data/data/model/all\\16-0.9354.hdf5\n",
      "\n",
      "Epoch 17: saving model to ./data/data/model/all\\17-0.9338.hdf5\n",
      "\n",
      "Epoch 18: saving model to ./data/data/model/all\\18-0.9362.hdf5\n",
      "\n",
      "Epoch 19: saving model to ./data/data/model/all\\19-0.9354.hdf5\n",
      "\n",
      "Epoch 20: saving model to ./data/data/model/all\\20-0.9362.hdf5\n",
      "\n",
      "Epoch 21: saving model to ./data/data/model/all\\21-0.9354.hdf5\n",
      "\n",
      "Epoch 22: saving model to ./data/data/model/all\\22-0.9354.hdf5\n",
      "\n",
      "Epoch 23: saving model to ./data/data/model/all\\23-0.9362.hdf5\n",
      "\n",
      "Epoch 24: saving model to ./data/data/model/all\\24-0.9369.hdf5\n",
      "\n",
      "Epoch 25: saving model to ./data/data/model/all\\25-0.9385.hdf5\n",
      "\n",
      "Epoch 26: saving model to ./data/data/model/all\\26-0.9377.hdf5\n",
      "\n",
      "Epoch 27: saving model to ./data/data/model/all\\27-0.9400.hdf5\n",
      "\n",
      "Epoch 28: saving model to ./data/data/model/all\\28-0.9408.hdf5\n",
      "\n",
      "Epoch 29: saving model to ./data/data/model/all\\29-0.9423.hdf5\n",
      "\n",
      "Epoch 30: saving model to ./data/data/model/all\\30-0.9431.hdf5\n",
      "\n",
      "Epoch 31: saving model to ./data/data/model/all\\31-0.9431.hdf5\n",
      "\n",
      "Epoch 32: saving model to ./data/data/model/all\\32-0.9415.hdf5\n",
      "\n",
      "Epoch 33: saving model to ./data/data/model/all\\33-0.9423.hdf5\n",
      "\n",
      "Epoch 34: saving model to ./data/data/model/all\\34-0.9438.hdf5\n",
      "\n",
      "Epoch 35: saving model to ./data/data/model/all\\35-0.9431.hdf5\n",
      "\n",
      "Epoch 36: saving model to ./data/data/model/all\\36-0.9454.hdf5\n",
      "\n",
      "Epoch 37: saving model to ./data/data/model/all\\37-0.9438.hdf5\n",
      "\n",
      "Epoch 38: saving model to ./data/data/model/all\\38-0.9454.hdf5\n",
      "\n",
      "Epoch 39: saving model to ./data/data/model/all\\39-0.9454.hdf5\n",
      "\n",
      "Epoch 40: saving model to ./data/data/model/all\\40-0.9462.hdf5\n",
      "\n",
      "Epoch 41: saving model to ./data/data/model/all\\41-0.9454.hdf5\n",
      "\n",
      "Epoch 42: saving model to ./data/data/model/all\\42-0.9469.hdf5\n",
      "\n",
      "Epoch 43: saving model to ./data/data/model/all\\43-0.9469.hdf5\n",
      "\n",
      "Epoch 44: saving model to ./data/data/model/all\\44-0.9469.hdf5\n",
      "\n",
      "Epoch 45: saving model to ./data/data/model/all\\45-0.9469.hdf5\n",
      "\n",
      "Epoch 46: saving model to ./data/data/model/all\\46-0.9477.hdf5\n",
      "\n",
      "Epoch 47: saving model to ./data/data/model/all\\47-0.9477.hdf5\n",
      "\n",
      "Epoch 48: saving model to ./data/data/model/all\\48-0.9469.hdf5\n",
      "\n",
      "Epoch 49: saving model to ./data/data/model/all\\49-0.9485.hdf5\n",
      "\n",
      "Epoch 50: saving model to ./data/data/model/all\\50-0.9485.hdf5\n",
      "\n",
      "Epoch 51: saving model to ./data/data/model/all\\51-0.9492.hdf5\n",
      "\n",
      "Epoch 52: saving model to ./data/data/model/all\\52-0.9492.hdf5\n",
      "\n",
      "Epoch 53: saving model to ./data/data/model/all\\53-0.9523.hdf5\n",
      "\n",
      "Epoch 54: saving model to ./data/data/model/all\\54-0.9531.hdf5\n",
      "\n",
      "Epoch 55: saving model to ./data/data/model/all\\55-0.9531.hdf5\n",
      "\n",
      "Epoch 56: saving model to ./data/data/model/all\\56-0.9562.hdf5\n",
      "\n",
      "Epoch 57: saving model to ./data/data/model/all\\57-0.9523.hdf5\n",
      "\n",
      "Epoch 58: saving model to ./data/data/model/all\\58-0.9562.hdf5\n",
      "\n",
      "Epoch 59: saving model to ./data/data/model/all\\59-0.9531.hdf5\n",
      "\n",
      "Epoch 60: saving model to ./data/data/model/all\\60-0.9569.hdf5\n",
      "\n",
      "Epoch 61: saving model to ./data/data/model/all\\61-0.9531.hdf5\n",
      "\n",
      "Epoch 62: saving model to ./data/data/model/all\\62-0.9569.hdf5\n",
      "\n",
      "Epoch 63: saving model to ./data/data/model/all\\63-0.9569.hdf5\n",
      "\n",
      "Epoch 64: saving model to ./data/data/model/all\\64-0.9569.hdf5\n",
      "\n",
      "Epoch 65: saving model to ./data/data/model/all\\65-0.9577.hdf5\n",
      "\n",
      "Epoch 66: saving model to ./data/data/model/all\\66-0.9577.hdf5\n",
      "\n",
      "Epoch 67: saving model to ./data/data/model/all\\67-0.9569.hdf5\n",
      "\n",
      "Epoch 68: saving model to ./data/data/model/all\\68-0.9577.hdf5\n",
      "\n",
      "Epoch 69: saving model to ./data/data/model/all\\69-0.9577.hdf5\n",
      "\n",
      "Epoch 70: saving model to ./data/data/model/all\\70-0.9562.hdf5\n",
      "\n",
      "Epoch 71: saving model to ./data/data/model/all\\71-0.9585.hdf5\n",
      "\n",
      "Epoch 72: saving model to ./data/data/model/all\\72-0.9585.hdf5\n",
      "\n",
      "Epoch 73: saving model to ./data/data/model/all\\73-0.9585.hdf5\n",
      "\n",
      "Epoch 74: saving model to ./data/data/model/all\\74-0.9592.hdf5\n",
      "\n",
      "Epoch 75: saving model to ./data/data/model/all\\75-0.9615.hdf5\n",
      "\n",
      "Epoch 76: saving model to ./data/data/model/all\\76-0.9592.hdf5\n",
      "\n",
      "Epoch 77: saving model to ./data/data/model/all\\77-0.9638.hdf5\n",
      "\n",
      "Epoch 78: saving model to ./data/data/model/all\\78-0.9608.hdf5\n",
      "\n",
      "Epoch 79: saving model to ./data/data/model/all\\79-0.9600.hdf5\n",
      "\n",
      "Epoch 80: saving model to ./data/data/model/all\\80-0.9608.hdf5\n",
      "\n",
      "Epoch 81: saving model to ./data/data/model/all\\81-0.9615.hdf5\n",
      "\n",
      "Epoch 82: saving model to ./data/data/model/all\\82-0.9662.hdf5\n",
      "\n",
      "Epoch 83: saving model to ./data/data/model/all\\83-0.9623.hdf5\n",
      "\n",
      "Epoch 84: saving model to ./data/data/model/all\\84-0.9654.hdf5\n",
      "\n",
      "Epoch 85: saving model to ./data/data/model/all\\85-0.9600.hdf5\n",
      "\n",
      "Epoch 86: saving model to ./data/data/model/all\\86-0.9669.hdf5\n",
      "\n",
      "Epoch 87: saving model to ./data/data/model/all\\87-0.9646.hdf5\n",
      "\n",
      "Epoch 88: saving model to ./data/data/model/all\\88-0.9700.hdf5\n",
      "\n",
      "Epoch 89: saving model to ./data/data/model/all\\89-0.9615.hdf5\n",
      "\n",
      "Epoch 90: saving model to ./data/data/model/all\\90-0.9677.hdf5\n",
      "\n",
      "Epoch 91: saving model to ./data/data/model/all\\91-0.9685.hdf5\n",
      "\n",
      "Epoch 92: saving model to ./data/data/model/all\\92-0.9677.hdf5\n",
      "\n",
      "Epoch 93: saving model to ./data/data/model/all\\93-0.9715.hdf5\n",
      "\n",
      "Epoch 94: saving model to ./data/data/model/all\\94-0.9723.hdf5\n",
      "\n",
      "Epoch 95: saving model to ./data/data/model/all\\95-0.9662.hdf5\n",
      "\n",
      "Epoch 96: saving model to ./data/data/model/all\\96-0.9677.hdf5\n",
      "\n",
      "Epoch 97: saving model to ./data/data/model/all\\97-0.9746.hdf5\n",
      "\n",
      "Epoch 98: saving model to ./data/data/model/all\\98-0.9777.hdf5\n",
      "\n",
      "Epoch 99: saving model to ./data/data/model/all\\99-0.9738.hdf5\n",
      "\n",
      "Epoch 100: saving model to ./data/data/model/all\\100-0.9731.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x250fff7b070>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_path = './data/data/model/all/{epoch:02d}-{val_accuracy:.4f}.hdf5'\n",
    "# epoch 실행시 마다 모델을 파일로 저장\n",
    "checkpointer = ModelCheckpoint(filepath=model_path, verbose=True)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 실행 : callbacks를 설정\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=500, validation_split=0.25, verbose=0,\n",
    "         callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed9b3eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history['accuracy'].index(max(model.history.history['accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46905611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 실행 : callbacks를 설정\n",
    "history=model.fit(X_train, y_train, epochs=2000, batch_size=500, validation_split=0.25, verbose=0,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b090b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.062552</td>\n",
       "      <td>0.218373</td>\n",
       "      <td>0.808053</td>\n",
       "      <td>0.214615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.719673</td>\n",
       "      <td>0.549654</td>\n",
       "      <td>0.685574</td>\n",
       "      <td>0.862308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.685375</td>\n",
       "      <td>0.849115</td>\n",
       "      <td>0.682076</td>\n",
       "      <td>0.846923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.671283</td>\n",
       "      <td>0.842956</td>\n",
       "      <td>0.617181</td>\n",
       "      <td>0.852308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.456898</td>\n",
       "      <td>0.831665</td>\n",
       "      <td>0.373980</td>\n",
       "      <td>0.829231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  1.062552  0.218373  0.808053      0.214615\n",
       "1  0.719673  0.549654  0.685574      0.862308\n",
       "2  0.685375  0.849115  0.682076      0.846923\n",
       "3  0.671283  0.842956  0.617181      0.852308\n",
       "4  0.456898  0.831665  0.373980      0.829231"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hist_df = pd.DataFrame(history.history)\n",
    "hist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a1330f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프로 확인 ( 에러 -> 손실함수의 결과)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "479a6e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_vloss = hist_df['val_loss']\n",
    "y_loss = hist_df['loss']\n",
    "\n",
    "x_len = np.arange(len(y_vloss))\n",
    "plt.plot(x_len, y_vloss, 'o',markersize=1, c='red', label='Test_loss')\n",
    "plt.plot(x_len, y_loss, 'o',markersize=1, c='blue', label='Train_loss')\n",
    "plt.legend()\n",
    "plt.ylim(0,0.7)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef905ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 종단점 설정\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0f65455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0309 - accuracy: 0.9910 - val_loss: 0.0342 - val_accuracy: 0.9908\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0320 - accuracy: 0.9905 - val_loss: 0.0346 - val_accuracy: 0.9908\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0302 - accuracy: 0.9905 - val_loss: 0.0336 - val_accuracy: 0.9900\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0312 - accuracy: 0.9887 - val_loss: 0.0358 - val_accuracy: 0.9908\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0306 - accuracy: 0.9902 - val_loss: 0.0355 - val_accuracy: 0.9908\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0307 - accuracy: 0.9913 - val_loss: 0.0326 - val_accuracy: 0.9900\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0308 - accuracy: 0.9908 - val_loss: 0.0333 - val_accuracy: 0.9908\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0307 - accuracy: 0.9902 - val_loss: 0.0357 - val_accuracy: 0.9915\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0317 - accuracy: 0.9892 - val_loss: 0.0382 - val_accuracy: 0.9915\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0309 - accuracy: 0.9905 - val_loss: 0.0326 - val_accuracy: 0.9900\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0307 - accuracy: 0.9913 - val_loss: 0.0333 - val_accuracy: 0.9892\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0313 - accuracy: 0.9900 - val_loss: 0.0320 - val_accuracy: 0.9908\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0313 - accuracy: 0.9902 - val_loss: 0.0390 - val_accuracy: 0.9900\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0312 - accuracy: 0.9910 - val_loss: 0.0337 - val_accuracy: 0.9915\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0312 - accuracy: 0.9905 - val_loss: 0.0326 - val_accuracy: 0.9900\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0296 - accuracy: 0.9910 - val_loss: 0.0350 - val_accuracy: 0.9908\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0311 - accuracy: 0.9905 - val_loss: 0.0350 - val_accuracy: 0.9900\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0306 - accuracy: 0.9915 - val_loss: 0.0325 - val_accuracy: 0.9900\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0306 - accuracy: 0.9908 - val_loss: 0.0322 - val_accuracy: 0.9908\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0304 - accuracy: 0.9905 - val_loss: 0.0364 - val_accuracy: 0.9915\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0314 - accuracy: 0.9908 - val_loss: 0.0352 - val_accuracy: 0.9908\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0340 - accuracy: 0.9892 - val_loss: 0.0345 - val_accuracy: 0.9908\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0316 - accuracy: 0.9900 - val_loss: 0.0327 - val_accuracy: 0.9908\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0304 - accuracy: 0.9908 - val_loss: 0.0337 - val_accuracy: 0.9900\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0321 - accuracy: 0.9895 - val_loss: 0.0325 - val_accuracy: 0.9900\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0304 - accuracy: 0.9902 - val_loss: 0.0333 - val_accuracy: 0.9900\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0309 - accuracy: 0.9910 - val_loss: 0.0362 - val_accuracy: 0.9915\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0315 - accuracy: 0.9910 - val_loss: 0.0332 - val_accuracy: 0.9908\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0307 - accuracy: 0.9892 - val_loss: 0.0401 - val_accuracy: 0.9892\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0347 - accuracy: 0.9895 - val_loss: 0.0547 - val_accuracy: 0.9831\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0403 - accuracy: 0.9854 - val_loss: 0.0557 - val_accuracy: 0.9823\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0407 - accuracy: 0.9869 - val_loss: 0.0323 - val_accuracy: 0.9915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x250ffb678b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_callback = EarlyStopping(patience=20)\n",
    "checkpointer = ModelCheckpoint(filepath=model_path, verbose=0, save_best_only=True)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=500, validation_split=0.25, verbose=1, callbacks=[early_stopping_callback, checkpointer])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
